import { GoogleGenAI, Schema, Type } from "@google/genai";
import { GeneratedThread, SlideData } from "../types";

const parseBase64 = (dataUrl: string) => {
  return dataUrl.split(',')[1];
};

export const generateThreadContent = async (slides: SlideData[]): Promise<GeneratedThread> => {
  if (!process.env.API_KEY) {
    throw new Error("API Key is missing.");
  }

  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  // Prepare input parts: Text prompt + All images
  const parts: any[] = [];

  // System instruction / Prompt
  const promptText = `
    ã‚ãªãŸã¯SNSé‹ç”¨ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
    ä»¥ä¸‹ã®ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‚’åˆ†æžã—ã€Twitter/Xã®ã‚¹ãƒ¬ãƒƒãƒ‰æŠ•ç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    å„ã‚¹ãƒ©ã‚¤ãƒ‰ã«ã¤ã„ã¦ä»¥ä¸‹ã®2ç‚¹ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

    1. threadPost:
       å…¨ã¦ã®ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ˆ1æžšç›®ã‚’å«ã‚€ï¼‰ã§ã€ä»¥ä¸‹ã®æ§‹æˆãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã‚’åŽ³å®ˆã—ã¦ãã ã•ã„ã€‚é•·æ–‡ã¯é¿ã‘ã€è¦–èªæ€§ã‚’æœ€å„ªå…ˆã—ã¾ã™ã€‚

         (a) 1è¡Œç›®: ã€è¦‹å‡ºã—ã€‘ ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ã®å†…å®¹ã‚’ç«¯çš„ã«è¡¨ã™ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
         (b) æœ¬æ–‡: ç°¡æ½”ãªç®‡æ¡æ›¸ãã€‚
             - æ–‡æœ«ã¯ã€Œã€œã§ã™/ã¾ã™ã€ã§ã¯ãªãã€ä½“è¨€æ­¢ã‚ã‚„åè©žæ­¢ã‚ã§çŸ­ãåˆ‡ã‚‹ã€‚
             - 1æžšç›®ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚‚ã€ã‚¹ãƒ¬ãƒƒãƒ‰ã®å°Žå…¥ã¨ã—ã¦æ©Ÿèƒ½ã—ã¤ã¤ã€ã“ã®ç®‡æ¡æ›¸ãå½¢å¼ã‚’å®ˆã‚‹ã“ã¨ã€‚
         (c) ç®‡æ¡æ›¸ãã®è¡Œé ­: ãã®ãƒ„ã‚¤ãƒ¼ãƒˆå†…ã§ä½¿ç”¨ã™ã‚‹çµµæ–‡å­—ã¯ã€Œ1ç¨®é¡žã«å›ºå®šã€ã™ã‚‹ã€‚
             - ãŸã ã—ã€ãƒ„ã‚¤ãƒ¼ãƒˆã”ã¨ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ã”ã¨ï¼‰ã«ç•°ãªã‚‹çµµæ–‡å­—ã‚’ä½¿ç”¨ã—ã€ã‚¹ãƒ¬ãƒƒãƒ‰å…¨ä½“ã§å˜èª¿ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã€‚
             (è‰¯ã„ä¾‹ - ãƒ„ã‚¤ãƒ¼ãƒˆA:
               ðŸ”¥ ãƒã‚¤ãƒ³ãƒˆA
               ðŸ”¥ ãƒã‚¤ãƒ³ãƒˆB
               ðŸ”¥ ãƒã‚¤ãƒ³ãƒˆC
             )
             (è‰¯ã„ä¾‹ - ãƒ„ã‚¤ãƒ¼ãƒˆB:
               ðŸ’¡ ãƒã‚¤ãƒ³ãƒˆX
               ðŸ’¡ ãƒã‚¤ãƒ³ãƒˆY
             )
             (æ‚ªã„ä¾‹ - çµµæ–‡å­—æ··åœ¨:
               ðŸ”¥ ãƒã‚¤ãƒ³ãƒˆA
               â­ï¸ ãƒã‚¤ãƒ³ãƒˆB
             )

    2. imageDescription: 
       - ãã®ç”»åƒãŒä½•ã‚’è¡¨ã—ã¦ã„ã‚‹ã‹ã®å®¢è¦³çš„ã§è©³ç´°ãªèª¬æ˜Žæ–‡ï¼ˆAlt textç”¨ï¼‰ã€‚

    å‡ºåŠ›ã¯JSONå½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
  `;

  parts.push({ text: promptText });

  // Add images
  // Note: Depending on the total payload size, sending too many high-res images might hit limits.
  // Gemini 2.5 Flash has a large context window, so ~20-30 slides usually fit fine.
  slides.forEach((slide) => {
    parts.push({
      inlineData: {
        mimeType: "image/png",
        data: parseBase64(slide.imageData),
      },
    });
  });

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      items: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            slideIndex: { type: Type.INTEGER, description: "0-based index of the slide corresponding to this text" },
            threadPost: { type: Type.STRING, description: "The social media post text for this slide" },
            imageDescription: { type: Type.STRING, description: "Accessibility description of the image" },
          },
          required: ["slideIndex", "threadPost", "imageDescription"],
        },
      },
    },
    required: ["items"],
  };

  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: {
        role: "user",
        parts: parts
      },
      config: {
        responseMimeType: "application/json",
        responseSchema: schema,
        systemInstruction: "You are a helpful social media assistant specializing in technical and educational content.",
      }
    });

    const text = response.text;
    if (!text) throw new Error("No response from Gemini");

    return JSON.parse(text) as GeneratedThread;
  } catch (error) {
    console.error("Gemini API Error:", error);
    throw error;
  }
};